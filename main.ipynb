{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inbuilt Python modules\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Imports required for Selenium Chromedriver\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support.expected_conditions import presence_of_element_located as poel\n",
    "\n",
    "# Function to get the Google search URL\n",
    "def get_google_search_url(query,recency):\n",
    "    query = query.replace(' ', '+')\n",
    "    url = f\"https://duckduckgo.com/?q={query}&ia=web\"\n",
    "    \n",
    "    if recency != \"\":\n",
    "        url += f\"&df={recency}\"\n",
    "    \n",
    "    return url\n",
    "# defining driver\n",
    "opt = Options()\n",
    "opt.add_argument(\"--start-maximized\")\n",
    "\n",
    "# doesn't wait for the page to complete loading\n",
    "caps = DesiredCapabilities.CHROME\n",
    "caps[\"pageLoadStrategy\"] = \"eager\"\n",
    "\n",
    "service = Service(\"./chromedriver.exe\")\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=service, \n",
    "    options=opt, \n",
    "    desired_capabilities= caps\n",
    ")\n",
    "\n",
    "wait = WebDriverWait(driver, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat : 52 results\n",
      "dog : 48 results\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"cat\",\n",
    "    \"dog\"\n",
    "]\n",
    "# max times it will click more results\n",
    "pages = 10\n",
    "# can be out of \"d\", \"w\", \"m\", \"y\", \"\"\n",
    "recency = \"m\" \n",
    "\n",
    "# Domains to avoid\n",
    "avoid = [\n",
    "    \"amazon\",\n",
    "    \"wikipedia\",\n",
    "    \"imdb\",\n",
    "    \"duckduckgo\",\n",
    "    \"youtube\",\n",
    "    \"google\"\n",
    "]\n",
    "\n",
    "f_title = [\n",
    "    \"blog\"\n",
    "]\n",
    "\n",
    "\n",
    "for query in queries:\n",
    "    record = {\n",
    "        \"title\": [],\n",
    "        \"link\": [],\n",
    "        \"snippet\": []\n",
    "    }\n",
    "\n",
    "    driver.get(get_google_search_url(query, recency))\n",
    "    # while True:\n",
    "    body = wait.until(poel(\n",
    "        (By.TAG_NAME, \"body\")\n",
    "        ))\n",
    "\n",
    "    for i in range(pages):\n",
    "        try:\n",
    "            next_btn = wait.until(poel(\n",
    "                (By.ID, \"more-results\")\n",
    "                ))\n",
    "            action = ActionChains(driver)\n",
    "            action.move_to_element(next_btn)\n",
    "\n",
    "            action.perform()\n",
    "            next_btn.click()\n",
    "        except Exception as e:\n",
    "            break\n",
    "        time.sleep(1)\n",
    "\n",
    "    results = driver.find_elements(By.CSS_SELECTOR, 'li[data-layout=\"organic\"]')\n",
    "\n",
    "    i = 1\n",
    "    for result in results:\n",
    "        try:\n",
    "            link_tag = result.find_element(By.CSS_SELECTOR, 'a[data-testid=\"result-title-a\"]')\n",
    "            title = link_tag.text\n",
    "            link = link_tag.get_attribute(\"href\")\n",
    "\n",
    "            for domain in avoid:\n",
    "                if domain in link:\n",
    "                    continue\n",
    "\n",
    "            try:\n",
    "                snippet = result.find_element(By.CSS_SELECTOR, 'div[data-result=\"snippet\"]').text\n",
    "            except:\n",
    "                snippet = \"\"\n",
    "\n",
    "            if f:\n",
    "                for f in f_title:\n",
    "                    if (f.lower() in title.lower()) or (f.lower() in snippet.lower()):\n",
    "                        record[\"title\"].append(title)\n",
    "                        record[\"link\"].append(link)\n",
    "                        record[\"snippet\"].append(snippet)\n",
    "            else:\n",
    "                record[\"title\"].append(title)\n",
    "                record[\"link\"].append(link)\n",
    "                record[\"snippet\"].append(snippet)\n",
    "\n",
    "            i+=1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "    df = pd.DataFrame(record)\n",
    "    print(f\"{query} : {len(df)} results\")\n",
    "    df.to_csv(f\"./results/{query}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
